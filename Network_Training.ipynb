{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "\n",
    "from src.Dataset import HiC_Dataset\n",
    "from src.layers.WEGATConv import Deep_WEGAT_Conv\n",
    "from src.layers.utils import PositionalEncoding\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter, Linear, Sequential, Dropout\n",
    "from torch.utils.data import random_split\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "import torch_geometric as tgm\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn import TopKPooling as TKP\n",
    "from torch_geometric.nn import global_max_pool\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "\n",
    "DATASET = \"Data/test_dset_18features_custom_norm.pt\"\n",
    "NUMEPOCHS = 10\n",
    "BATCHSIZE = 500\n",
    "LEARNING_RATE = 0.00005\n",
    "WEIGHT_DECAY = 5e-4\n",
    "MANUAL_SEED = 40\n",
    "TRAIN_FRACTION = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "UTILITY FUNCTIONS\n",
    "'''\n",
    "def get_middle_features(x,\n",
    "                        numnodes = 51\n",
    "                       ):\n",
    "    mid = int((numnodes-1)/2)\n",
    "    idxs = torch.arange(mid, x.shape[0], numnodes)\n",
    "    return x[idxs,:]\n",
    "\n",
    "\n",
    "'''\n",
    "WEIGHTED EDGE GRAPH ATTENTION MODULE\n",
    "'''\n",
    "class WEGATModule(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 hidden_channels=20,\n",
    "                 numchip = 18,\n",
    "                 numedge = 3,\n",
    "                 heads = 4,\n",
    "                 num_graph_convs = 6,\n",
    "                 embedding_layers = 5,\n",
    "                 num_fc = 8,\n",
    "                 fc_channels = [15,15,15,10,10,10,5,2],\n",
    "                 num_prom_fc = 10,\n",
    "                 prom_fc_channels = [15,15,15,15,10,10,10,10,5,2],\n",
    "                 positional_encoding = True,\n",
    "                 pos_embedding_dropout = 0.1,\n",
    "                 fc_dropout = 0.5,\n",
    "                 conv_dropout = 0.1\n",
    "                ):\n",
    "        if isinstance(fc_channels,int):\n",
    "            fc_channels = [fc_channels]*num_fc\n",
    "        elif len(fc_channels) != num_fc:\n",
    "            print(\"number of fully connected channels must match the number of fully connected layers\")\n",
    "            raise\n",
    "\n",
    "        if num_graph_convs < 1:\n",
    "            print(\"need at least one graph convolution\")\n",
    "            raise\n",
    "        num_graph_convs = int(num_graph_convs)\n",
    "\n",
    "        if isinstance(prom_fc_channels,int):\n",
    "            prom_fc_channels = [prom_fc_channels]*num_prom_fc\n",
    "        elif len(prom_fc_channels) != num_prom_fc:\n",
    "            raise\n",
    "\n",
    "        super().__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        #dropout layer\n",
    "        self.dropout = Dropout(p=fc_dropout)\n",
    "\n",
    "        #number of input chip features\n",
    "        self.numchip = numchip\n",
    "\n",
    "        #Whether to apply positional encoding to nodes\n",
    "        self.positional_encoding = positional_encoding\n",
    "        if positional_encoding:\n",
    "            self.posencoder = PositionalEncoding(hidden_channels,\n",
    "                                                 dropout=pos_embedding_dropout,\n",
    "                                                 identical_sizes = True\n",
    "                                                )\n",
    "\n",
    "        #initial embeddding layer\n",
    "        embedding = []\n",
    "        embedding.append(Linear(numchip,\n",
    "                                hidden_channels)\n",
    "                        )\n",
    "        embedding.append(torch.nn.Dropout(p=fc_dropout))\n",
    "        embedding.append(torch.nn.ReLU())\n",
    "        for idx in torch.arange(embedding_layers - 1):\n",
    "            embedding.append(Linear(hidden_channels,\n",
    "                                    hidden_channels)\n",
    "                            )\n",
    "            embedding.append(torch.nn.Dropout(p=fc_dropout))\n",
    "            embedding.append(torch.nn.ReLU())\n",
    "        self.embedding = Sequential(*embedding)\n",
    "\n",
    "        #graph convolution layers\n",
    "        gconv = []\n",
    "        for idx in np.arange(num_graph_convs):\n",
    "            gconv.append(Deep_WEGAT_Conv(node_inchannels = hidden_channels,\n",
    "                                     node_outchannels = hidden_channels,\n",
    "                                     edge_inchannels = numedge,\n",
    "                                     edge_outchannels = numedge,\n",
    "                                     heads = heads,\n",
    "                                     node_dropout = conv_dropout,\n",
    "                                     edge_dropout = conv_dropout\n",
    "                                    )\n",
    "                        )\n",
    "\n",
    "        self.gconv = Sequential(*gconv)\n",
    "\n",
    "        #fully connected channels\n",
    "        fc_channels = [hidden_channels]+fc_channels\n",
    "        lin = []\n",
    "        for idx in torch.arange(num_fc):\n",
    "            lin.append(Linear(fc_channels[idx],fc_channels[idx+1]))\n",
    "            lin.append(torch.nn.Dropout(p=fc_dropout))\n",
    "            lin.append(torch.nn.ReLU())\n",
    "        self.lin = Sequential(*lin)\n",
    "        self.num_fc = num_fc\n",
    "\n",
    "        #fully connected promoter channels\n",
    "        prom_fc_channels = [numchip]+prom_fc_channels\n",
    "        linprom = []\n",
    "        for idx in torch.arange(num_prom_fc):\n",
    "            linprom.append(Linear(prom_fc_channels[idx],prom_fc_channels[idx+1]))\n",
    "            linprom.append(torch.nn.Dropout(p=fc_dropout))\n",
    "            linprom.append(torch.nn.ReLU())\n",
    "        self.linprom = Sequential(*linprom)\n",
    "        self.num_prom_fc = num_prom_fc\n",
    "\n",
    "        #final readout function\n",
    "        self.readout = Linear(prom_fc_channels[-1]+fc_channels[-1], 1)\n",
    "\n",
    "    def forward(self,\n",
    "                batch):\n",
    "        batch.prom_x = batch.prom_x.view(-1,self.numchip).float()\n",
    "        batch.edge_attr[torch.isnan(batch.edge_attr)] = 0\n",
    "        batch.x[torch.isnan(batch.x)] = 0\n",
    "        batch.prom_x[torch.isnan(batch.prom_x)] = 0\n",
    "        \n",
    "        #hack for now\n",
    "        batch.edge_attr[batch.edge_attr>100] = 100 \n",
    "        batch.edge_attr[:,:2] /= 100\n",
    "        \n",
    "        #initial dropout and embedding\n",
    "        batch.x = self.dropout(batch.x)\n",
    "        batch.x = self.embedding(batch.x.float())\n",
    "\n",
    "        #positional encoding\n",
    "        if self.positional_encoding:\n",
    "            batch.x = self.posencoder(batch.x,\n",
    "                                      batch.batch)\n",
    "\n",
    "        #graph convolutions\n",
    "        batch = self.gconv(batch)\n",
    "\n",
    "        #extracting node of interest from graph\n",
    "        x = get_middle_features(batch.x)\n",
    "\n",
    "        # 3. Apply fully connected linear layers to graph\n",
    "        x = self.lin(x)\n",
    "\n",
    "        # 3. Apply fully connected linear layers to promoter\n",
    "        prom_x = self.linprom(batch.prom_x)\n",
    "\n",
    "        r_x = torch.cat([x,prom_x],\n",
    "                        dim = 1)\n",
    "        \n",
    "        # 4. Apply readout layers\n",
    "        x = self.readout(r_x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightning Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "LIGHTNING NET\n",
    "'''\n",
    "class LitWEGATNet(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 module,\n",
    "                 train_loader,\n",
    "                 val_loader,\n",
    "                 learning_rate,\n",
    "                 numsteps\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.module = module\n",
    "        self.learning_rate = learning_rate\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.numsteps = numsteps\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.train_loader\n",
    "    def validation_dataloader(self):\n",
    "        return self.test_loader\n",
    "\n",
    "\n",
    "    def shared_step(self, batch):\n",
    "        pred = self.module(batch).squeeze()\n",
    "        idxs = abs(batch.y.float())>0.01\n",
    "        loss = F.l1_loss(pred[idxs], batch.y.float()[idxs])\n",
    "        return loss, pred\n",
    "\n",
    "    def customlog(self, name, loss, pred):\n",
    "        self.log(f'{name}_loss', loss)\n",
    "        self.log(f'{name}_maxabs_prediction',\n",
    "                 torch.max(abs(pred)).item())\n",
    "        self.log(f'{name}_mean_prediction',\n",
    "                 torch.mean(pred).item())\n",
    "        self.log(f'{name}_std_prediction',\n",
    "                 torch.std(pred).item())\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, pred = self.shared_step(batch)\n",
    "        self.customlog('train',loss, pred)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, pred = self.shared_step(batch)\n",
    "        self.customlog('val',loss, pred)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, pred = self.shared_step(batch)\n",
    "        self.customlog('test',loss, pred)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(),\n",
    "                                     lr=self.learning_rate)\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': OneCycleLR(optimizer,\n",
    "                                        max_lr = 10*self.learning_rate,\n",
    "                                        total_steps = self.numsteps\n",
    "                                       )\n",
    "            }\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in memory datasets\n",
      "Loaded in memory datasets\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "CONSTRUCTING THE DATALOADERS\n",
    "'''\n",
    "print(\"Loading in memory datasets\")\n",
    "dset = torch.load(DATASET,map_location=torch.device('cpu'))\n",
    "\n",
    "numdatapoints = len(dset)\n",
    "trainsize = int(numdatapoints*TRAIN_FRACTION)\n",
    "train_dset, val_dset = random_split(dset,\n",
    "                                    [trainsize, numdatapoints-trainsize],\n",
    "                                    generator=torch.Generator().manual_seed(MANUAL_SEED)\n",
    "                                   )\n",
    "\n",
    "print(\"Loaded in memory datasets\")\n",
    "train_loader = DataLoader(train_dset, \n",
    "                              batch_size=BATCHSIZE,\n",
    "                              num_workers=20\n",
    "                             )\n",
    "val_loader = DataLoader(val_dset, \n",
    "                             batch_size=BATCHSIZE,\n",
    "                            num_workers=20\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nvals = []\\ni = 0\\nfor dat in train_loader:\\n    vals.append(dat.y.detach().numpy())\\n    i+=1\\n    if i > 500:\\n        break\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "vals = []\n",
    "i = 0\n",
    "for dat in train_loader:\n",
    "    vals.append(dat.y.detach().numpy())\n",
    "    i+=1\n",
    "    if i > 500:\n",
    "        break\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nvals = np.concatenate(vals)\\nvals = vals[~((vals<0.01)&(vals>-0.01))]\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "vals = np.concatenate(vals)\n",
    "vals = vals[~((vals<0.01)&(vals>-0.01))]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nwith plt.xkcd():\\n    fig = plt.figure()\\n    ax = fig.add_axes((0.1, 0.2, 0.8, 0.7))\\n    ax.spines['right'].set_color('none')\\n    ax.spines['top'].set_color('none')\\n    #ax.set_xticks([])\\n    ax.set_yticks([])\\n    h=ax.hist(vals,bins = 100)\\n    ax.set_xlim([-0.5,0.5])\\n\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "with plt.xkcd():\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes((0.1, 0.2, 0.8, 0.7))\n",
    "    ax.spines['right'].set_color('none')\n",
    "    ax.spines['top'].set_color('none')\n",
    "    #ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    h=ax.hist(vals,bins = 100)\n",
    "    ax.set_xlim([-0.5,0.5])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nidx = np.argmax(h[0].astype('int'))\\nh[1][idx:idx+2]\\n\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "idx = np.argmax(h[0].astype('int'))\n",
    "h[1][idx:idx+2]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################LAYER########################\n",
      "INPUT FEATURES\n",
      "nodes:\n",
      "\tmin:\t-0.9999129772186279\n",
      "\tmax:\t1.2642322778701782\n",
      "\tmean:\t0.42540255188941956\n",
      "edges:\n",
      "\tmin:\t0.0\n",
      "\tmax:\t1.0\n",
      "\tmean:\t0.1499070757256292\n",
      "MESSAGES\n",
      "nodes:\n",
      "\tmin:\t-0.4545431137084961\n",
      "\tmax:\t2.1450958251953125\n",
      "\tmean:\t0.36135536432266235\n",
      "edges:\n",
      "\tmin:\t-1.4297250509262085\n",
      "\tmax:\t2.1160027980804443\n",
      "\tmean:\t0.06548897176980972\n",
      "OUTPUT FEATURES\n",
      "nodes:\n",
      "\tmin:\t-0.8205474019050598\n",
      "\tmax:\t1.9046975374221802\n",
      "\tmean:\t0.585176408290863\n",
      "edges:\n",
      "\tmin:\t-1.0112165236799333\n",
      "\tmax:\t1.5778392140832698\n",
      "\tmean:\t0.06515128093188206\n",
      "############################LAYER########################\n",
      "INPUT FEATURES\n",
      "nodes:\n",
      "\tmin:\t-0.8205474019050598\n",
      "\tmax:\t1.9046975374221802\n",
      "\tmean:\t0.585176408290863\n",
      "edges:\n",
      "\tmin:\t-1.0112165236799333\n",
      "\tmax:\t1.5778392140832698\n",
      "\tmean:\t0.06515128093188206\n",
      "MESSAGES\n",
      "nodes:\n",
      "\tmin:\t-0.4124680161476135\n",
      "\tmax:\t1.6783734560012817\n",
      "\tmean:\t0.42786648869514465\n",
      "edges:\n",
      "\tmin:\t-0.15496711432933807\n",
      "\tmax:\t5.026882648468018\n",
      "\tmean:\t0.33499783277511597\n",
      "OUTPUT FEATURES\n",
      "nodes:\n",
      "\tmin:\t-0.5684245228767395\n",
      "\tmax:\t1.8295435905456543\n",
      "\tmean:\t0.5989341735839844\n",
      "edges:\n",
      "\tmin:\t-0.05323789803364599\n",
      "\tmax:\t1.3384937276730766\n",
      "\tmean:\t0.12668725336694914\n",
      "############################LAYER########################\n",
      "INPUT FEATURES\n",
      "nodes:\n",
      "\tmin:\t-0.5684245228767395\n",
      "\tmax:\t1.8295435905456543\n",
      "\tmean:\t0.5989341735839844\n",
      "edges:\n",
      "\tmin:\t-0.05323789803364599\n",
      "\tmax:\t1.3384937276730766\n",
      "\tmean:\t0.12668725336694914\n",
      "MESSAGES\n",
      "nodes:\n",
      "\tmin:\t-0.7729548215866089\n",
      "\tmax:\t1.8806543350219727\n",
      "\tmean:\t0.4661310613155365\n",
      "edges:\n",
      "\tmin:\t-0.10742029547691345\n",
      "\tmax:\t1.8040496110916138\n",
      "\tmean:\t0.08988060057163239\n",
      "OUTPUT FEATURES\n",
      "nodes:\n",
      "\tmin:\t-0.941149115562439\n",
      "\tmax:\t1.9579691886901855\n",
      "\tmean:\t0.6051859855651855\n",
      "edges:\n",
      "\tmin:\t-0.07020392038242991\n",
      "\tmax:\t1.5428033375350652\n",
      "\tmean:\t0.11272393356528143\n",
      "############################LAYER########################\n",
      "INPUT FEATURES\n",
      "nodes:\n",
      "\tmin:\t-0.941149115562439\n",
      "\tmax:\t1.9579691886901855\n",
      "\tmean:\t0.6051859855651855\n",
      "edges:\n",
      "\tmin:\t-0.07020392038242991\n",
      "\tmax:\t1.5428033375350652\n",
      "\tmean:\t0.11272393356528143\n",
      "MESSAGES\n",
      "nodes:\n",
      "\tmin:\t-0.5075539350509644\n",
      "\tmax:\t1.9626492261886597\n",
      "\tmean:\t0.4194853603839874\n",
      "edges:\n",
      "\tmin:\t0.0\n",
      "\tmax:\t4.934064865112305\n",
      "\tmean:\t0.4242408871650696\n",
      "OUTPUT FEATURES\n",
      "nodes:\n",
      "\tmin:\t-0.7854175567626953\n",
      "\tmax:\t2.1669394969940186\n",
      "\tmean:\t0.5886439085006714\n",
      "edges:\n",
      "\tmin:\t0.0\n",
      "\tmax:\t1.1551568390515143\n",
      "\tmean:\t0.1315006205075454\n",
      "############################LAYER########################\n",
      "INPUT FEATURES\n",
      "nodes:\n",
      "\tmin:\t-0.7854175567626953\n",
      "\tmax:\t2.1669394969940186\n",
      "\tmean:\t0.5886439085006714\n",
      "edges:\n",
      "\tmin:\t0.0\n",
      "\tmax:\t1.1551568390515143\n",
      "\tmean:\t0.1315006205075454\n",
      "MESSAGES\n",
      "nodes:\n",
      "\tmin:\t-0.6450448036193848\n",
      "\tmax:\t1.6180795431137085\n",
      "\tmean:\t0.4924083948135376\n",
      "edges:\n",
      "\tmin:\t-0.0297809187322855\n",
      "\tmax:\t3.5510003566741943\n",
      "\tmean:\t0.21642029285430908\n",
      "OUTPUT FEATURES\n",
      "nodes:\n",
      "\tmin:\t-0.7398678064346313\n",
      "\tmax:\t1.9034414291381836\n",
      "\tmean:\t0.6236792802810669\n",
      "edges:\n",
      "\tmin:\t-0.08395633878058005\n",
      "\tmax:\t1.4082432476846576\n",
      "\tmean:\t0.12252892416687786\n",
      "############################LAYER########################\n",
      "INPUT FEATURES\n",
      "nodes:\n",
      "\tmin:\t-0.7398678064346313\n",
      "\tmax:\t1.9034414291381836\n",
      "\tmean:\t0.6236792802810669\n",
      "edges:\n",
      "\tmin:\t-0.08395633878058005\n",
      "\tmax:\t1.4082432476846576\n",
      "\tmean:\t0.12252892416687786\n",
      "MESSAGES\n",
      "nodes:\n",
      "\tmin:\t-0.5233166813850403\n",
      "\tmax:\t1.8596150875091553\n",
      "\tmean:\t0.49210941791534424\n",
      "edges:\n",
      "\tmin:\t-0.10306014865636826\n",
      "\tmax:\t1.9927606582641602\n",
      "\tmean:\t0.15825434029102325\n",
      "OUTPUT FEATURES\n",
      "nodes:\n",
      "\tmin:\t-0.6975904703140259\n",
      "\tmax:\t1.8285927772521973\n",
      "\tmean:\t0.6221224069595337\n",
      "edges:\n",
      "\tmin:\t-0.30456480833012617\n",
      "\tmax:\t1.274310362086007\n",
      "\tmean:\t0.12990029133882874\n"
     ]
    }
   ],
   "source": [
    "NUMCHIP = dset[0].x.shape[1]\n",
    "NUMEDGE = dset[0].edge_attr.shape[1]\n",
    "module = WEGATModule(hidden_channels = 20,\n",
    "                         numchip = NUMCHIP,\n",
    "                         numedge = NUMEDGE,\n",
    "                         embedding_layers = 4,\n",
    "                         positional_encoding = True,\n",
    "                         pos_embedding_dropout = 0,\n",
    "                         fc_dropout = 0,\n",
    "                         conv_dropout = 0\n",
    "                        )\n",
    "for dat in val_loader:\n",
    "    module(dat)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name   | Type        | Params\n",
      "---------------------------------------\n",
      "0 | module | WEGATModule | 15.4 K\n",
      "---------------------------------------\n",
      "15.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.4 K    Total params\n",
      "0.062     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X pre processing\n",
      "tensor(0.3971, dtype=torch.float64) tensor(1., dtype=torch.float64) tensor(0., dtype=torch.float64)\n",
      "X post embedding\n",
      "tensor(0.0427) tensor(0.2669) tensor(0.)\n",
      "X post positional encoding\n",
      "tensor(0.4254) tensor(1.2642) tensor(-0.9999)\n",
      "X post graph convolutions\n",
      "tensor(0.) tensor(0.) tensor(0.)\n",
      "X post processing\n",
      "tensor(0.) tensor(0.) tensor(0.)\n",
      "X pre processing\n",
      "tensor(0.3866, dtype=torch.float64) tensor(1., dtype=torch.float64) tensor(0., dtype=torch.float64)\n",
      "X post embedding\n",
      "tensor(0.0428) tensor(0.2668) tensor(0.)\n",
      "X post positional encoding\n",
      "tensor(0.4254) tensor(1.2651) tensor(-0.9999)\n",
      "X post graph convolutions\n",
      "tensor(0.) tensor(0.) tensor(0.)\n",
      "X post processing\n",
      "tensor(0.) tensor(0.) tensor(0.)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "003ff25155444cc7bf4e6c1e78c38e6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X pre processing\n",
      "tensor(0.3989, dtype=torch.float64) tensor(1., dtype=torch.float64) tensor(0., dtype=torch.float64)\n",
      "X post embedding\n",
      "tensor(0.2408, grad_fn=<MeanBackward0>) tensor(430.0927, grad_fn=<MaxBackward1>) tensor(0., grad_fn=<MinBackward1>)\n",
      "X post positional encoding\n",
      "tensor(0.6270, grad_fn=<MeanBackward0>) tensor(3252.6562, grad_fn=<MaxBackward1>) tensor(-9.9999, grad_fn=<MinBackward1>)\n",
      "X post graph convolutions\n",
      "tensor(0., grad_fn=<MeanBackward0>) tensor(0., grad_fn=<MaxBackward1>) tensor(0., grad_fn=<MinBackward1>)\n",
      "X post processing\n",
      "tensor(0., grad_fn=<MeanBackward0>) tensor(0., grad_fn=<MaxBackward1>) tensor(0., grad_fn=<MinBackward1>)\n",
      "X pre processing\n",
      "tensor(0.4027, dtype=torch.float64) tensor(1., dtype=torch.float64) tensor(0., dtype=torch.float64)\n",
      "X post embedding\n",
      "tensor(0.2327, grad_fn=<MeanBackward0>) tensor(391.0336, grad_fn=<MaxBackward1>) tensor(0., grad_fn=<MinBackward1>)\n",
      "X post positional encoding\n",
      "tensor(0.6108, grad_fn=<MeanBackward0>) tensor(1876.0699, grad_fn=<MaxBackward1>) tensor(-9.9999, grad_fn=<MinBackward1>)\n",
      "X post graph convolutions\n",
      "tensor(0., grad_fn=<MeanBackward0>) tensor(0., grad_fn=<MaxBackward1>) tensor(0., grad_fn=<MinBackward1>)\n",
      "X post processing\n",
      "tensor(0., grad_fn=<MeanBackward0>) tensor(0., grad_fn=<MaxBackward1>) tensor(0., grad_fn=<MinBackward1>)\n",
      "X pre processing\n",
      "tensor(0.4061, dtype=torch.float64) tensor(1., dtype=torch.float64) tensor(0., dtype=torch.float64)\n",
      "X post embedding\n",
      "tensor(0.2377, grad_fn=<MeanBackward0>) tensor(617.4684, grad_fn=<MaxBackward1>) tensor(0., grad_fn=<MinBackward1>)\n",
      "X post positional encoding\n",
      "tensor(0.6193, grad_fn=<MeanBackward0>) tensor(2050.0190, grad_fn=<MaxBackward1>) tensor(-9.9999, grad_fn=<MinBackward1>)\n",
      "X post graph convolutions\n",
      "tensor(0., grad_fn=<MeanBackward0>) tensor(0., grad_fn=<MaxBackward1>) tensor(0., grad_fn=<MinBackward1>)\n",
      "X post processing\n",
      "tensor(0., grad_fn=<MeanBackward0>) tensor(0., grad_fn=<MaxBackward1>) tensor(0., grad_fn=<MinBackward1>)\n",
      "X pre processing\n",
      "tensor(0.4070, dtype=torch.float64) tensor(1., dtype=torch.float64) tensor(0., dtype=torch.float64)\n",
      "X post embedding\n",
      "tensor(0.2404, grad_fn=<MeanBackward0>) tensor(536.1006, grad_fn=<MaxBackward1>) tensor(0., grad_fn=<MinBackward1>)\n",
      "X post positional encoding\n",
      "tensor(0.6605, grad_fn=<MeanBackward0>) tensor(5279.4756, grad_fn=<MaxBackward1>) tensor(-9.9999, grad_fn=<MinBackward1>)\n",
      "X post graph convolutions\n",
      "tensor(0., grad_fn=<MeanBackward0>) tensor(0., grad_fn=<MaxBackward1>) tensor(0., grad_fn=<MinBackward1>)\n",
      "X post processing\n",
      "tensor(0., grad_fn=<MeanBackward0>) tensor(0., grad_fn=<MaxBackward1>) tensor(0., grad_fn=<MinBackward1>)\n",
      "X pre processing\n",
      "tensor(0.4067, dtype=torch.float64) tensor(1., dtype=torch.float64) tensor(0., dtype=torch.float64)\n",
      "X post embedding\n",
      "tensor(0.2521, grad_fn=<MeanBackward0>) tensor(486.3310, grad_fn=<MaxBackward1>) tensor(0., grad_fn=<MinBackward1>)\n",
      "X post positional encoding\n",
      "tensor(0.6215, grad_fn=<MeanBackward0>) tensor(2163.1785, grad_fn=<MaxBackward1>) tensor(-9.9999, grad_fn=<MinBackward1>)\n",
      "X post graph convolutions\n",
      "tensor(0., grad_fn=<MeanBackward0>) tensor(0., grad_fn=<MaxBackward1>) tensor(0., grad_fn=<MinBackward1>)\n",
      "X post processing\n",
      "tensor(0., grad_fn=<MeanBackward0>) tensor(0., grad_fn=<MaxBackward1>) tensor(0., grad_fn=<MinBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x2b5aba7e23c8>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dh486/gnn-env/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1324, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dh486/gnn-env/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1297, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/local/software/master/python/3.6/lib/python3.6/multiprocessing/process.py\", line 124, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/usr/local/software/master/python/3.6/lib/python3.6/multiprocessing/popen_fork.py\", line 47, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/usr/local/software/master/python/3.6/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/local/software/master/python/3.6/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "NUMCHIP = dset[0].x.shape[1]\n",
    "NUMEDGE = dset[0].edge_attr.shape[1]\n",
    "\n",
    "module = WEGATModule(hidden_channels = 20,\n",
    "                         numchip = NUMCHIP,\n",
    "                         numedge = NUMEDGE,\n",
    "                         embedding_layers = 4,\n",
    "                         positional_encoding = True,\n",
    "                         pos_embedding_dropout = 0.9,\n",
    "                         fc_dropout = 0.9,\n",
    "                         conv_dropout = 0.9\n",
    "                        )\n",
    "Net = LitWEGATNet(module,\n",
    "                  train_loader,\n",
    "                  val_loader,\n",
    "                  LEARNING_RATE,\n",
    "                  50000)\n",
    "    \n",
    "\n",
    "tb_logger = pl_loggers.TensorBoardLogger('runs',\n",
    "                                         name = 'printing_test',\n",
    "                                         version = 0\n",
    "                                        )\n",
    "trainer = pl.Trainer(gpus=0,\n",
    "                     max_epochs=100,\n",
    "                     progress_bar_refresh_rate=1,\n",
    "                     #logger=tb_logger,\n",
    "                     auto_lr_find=False)\n",
    "\n",
    "trainer.fit(Net, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 255).\n",
       "Contents of stderr:\n",
       "TensorFlow installation not found - running with reduced feature set.\n",
       "E0519 13:54:06.474670 47233012180864 program.py:311] TensorBoard could not bind to port 8081, it was already in use\n",
       "ERROR: TensorBoard could not bind to port 8081, it was already in use"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start tensorboard.\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir runs/ --port=8081"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions.laplace import Laplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Laplace(torch.tensor([0.0]), torch.tensor([1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(394.5218, dtype=torch.float64, grad_fn=<NegBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = WEGATModule()\n",
    "for batch in train_loader:\n",
    "    pred = model(batch).squeeze()\n",
    "    print(-m.log_prob(pred-batch.y).sum())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "x = pd.read_table(\"Data/raw/target.tsv\")['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, figsize = (8,8))\n",
    "lim = 0.75\n",
    "numbins = 100\n",
    "h = ax.hist(x, bins = np.linspace(-lim,lim,numbins))\n",
    "ax.set_ylabel('Frequency',size = 20)\n",
    "ax.set_xlabel('Mbd3 KO--> WT\\nLog-fold Expression Change', size = 20)\n",
    "ax.tick_params(labelsize = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00757576,  0.00757576])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.argmax(h[0])\n",
    "h[1][idx:idx+2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.379006701018458"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h[0][idx]/np.sum(h[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04751191426566998"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(h[0][abs(h[1][:-1])>0.3])/np.sum(h[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
