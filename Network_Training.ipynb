{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from src.Dataset import HiC_Dataset\n",
    "from src.layers.WEGATConv import WEGATConv\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter, Linear, Sequential\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import torch_geometric as tgm\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn import TopKPooling as TKP\n",
    "from torch_geometric.nn import global_max_pool\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "\n",
    "DATASET = \"Data/test_dset_18features_custom_norm.pt\"\n",
    "NUMEPOCHS = 10\n",
    "BATCHSIZE = 500\n",
    "LEARNING_RATE = 0.00005\n",
    "WEIGHT_DECAY = 5e-4\n",
    "MANUAL_SEED = 40\n",
    "TRAIN_FRACTION = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "COMBINED 'WEIGHTED EDGE GRAPH ATTENTION' + 'TOP K POOLING LAYERS' \n",
    "'''\n",
    "class WEGAT_TOPK_Conv(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 node_inchannels,\n",
    "                 node_outchannels,\n",
    "                 edge_inchannels,\n",
    "                 edge_outchannels,\n",
    "                 heads = 4):\n",
    "        super().__init__()\n",
    "        self.conv = WEGATConv(in_channels = node_inchannels, \n",
    "                               node_out_channels = node_outchannels,\n",
    "                               edge_channels = edge_inchannels,\n",
    "                               edge_out_channels = edge_outchannels,\n",
    "                               heads = heads,\n",
    "                               concat = False\n",
    "                              )\n",
    "        self.pool = TKP(in_channels = node_outchannels)\n",
    "        \n",
    "    def forward(self, \n",
    "                batch):\n",
    "        batch.x, batch.edge_attr = self.conv(batch.x.float(),\n",
    "                                             batch.edge_attr.float(),\n",
    "                                             batch.edge_index)\n",
    "        batch.x = batch.x.relu()\n",
    "        batch.edge_attr = batch.edge_attr.relu()\n",
    "        batch.x, batch.edge_index, batch.edge_attr, batch.batch, perm,score = self.pool(batch.x,\n",
    "                                                                                        batch.edge_index,\n",
    "                                                                                        edge_attr = batch.edge_attr,\n",
    "                                                                                        batch = batch.batch)\n",
    "        \n",
    "        return batch\n",
    "        \n",
    "\n",
    "\n",
    "'''\n",
    "WEIGHTED EDGE GRAPH ATTENTION MODULE\n",
    "'''\n",
    "class WEGATModule(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                 hidden_channels,\n",
    "                 numchip = 18,\n",
    "                 numedge = 3,\n",
    "                 heads = 4,\n",
    "                 num_graph_convs = 3,\n",
    "                 num_fc = 5,\n",
    "                 fc_channels = [15,15,10,5,2],\n",
    "                 num_prom_fc = 5,\n",
    "                 prom_fc_channels = [15,15,10,5,2]\n",
    "                ):\n",
    "        if isinstance(fc_channels,int):\n",
    "            fc_channels = [fc_channels]*num_fc\n",
    "        elif len(fc_channels) != num_fc:\n",
    "            print(\"number of fully connected channels must match the number of fully connected layers\")\n",
    "            raise\n",
    "            \n",
    "        if num_graph_convs < 1:\n",
    "            print(\"need at least one graph convolution\")\n",
    "            raise\n",
    "        num_graph_convs = int(num_graph_convs)\n",
    "            \n",
    "        if isinstance(prom_fc_channels,int):\n",
    "            prom_fc_channels = [prom_fc_channels]*num_prom_fc\n",
    "        elif len(prom_fc_channels) != num_prom_fc:\n",
    "            raise\n",
    "        \n",
    "        super().__init__()\n",
    "        torch.manual_seed(12345)\n",
    "\n",
    "        self.loglikelihood_precision = Parameter(torch.tensor(0.))\n",
    "        gconv = [WEGAT_TOPK_Conv(node_inchannels = numchip, \n",
    "                             node_outchannels = hidden_channels,\n",
    "                             edge_inchannels = numedge,\n",
    "                             edge_outchannels = numedge,\n",
    "                             heads = heads\n",
    "                            )\n",
    "                ]\n",
    "        for idx in np.arange(num_graph_convs-1):\n",
    "            gconv.append(WEGAT_TOPK_Conv(node_inchannels = hidden_channels,\n",
    "                                     node_outchannels = hidden_channels,\n",
    "                                     edge_inchannels = numedge,\n",
    "                                     edge_outchannels = numedge,\n",
    "                                     heads = heads\n",
    "                                    )\n",
    "                        )\n",
    "\n",
    "        self.gconv = Sequential(*gconv)\n",
    "\n",
    "        fc_channels = [hidden_channels]+fc_channels\n",
    "        lin = []\n",
    "        for idx in torch.arange(num_fc):\n",
    "            lin.append(Linear(fc_channels[idx],fc_channels[idx+1]))\n",
    "            lin.append(torch.nn.ReLU())\n",
    "\n",
    "        self.lin = Sequential(*lin)\n",
    "        self.num_fc = num_fc\n",
    "        self.numchip = numchip\n",
    "        \n",
    "        prom_fc_channels = [numchip]+prom_fc_channels\n",
    "        linprom = []\n",
    "        for idx in torch.arange(num_prom_fc):\n",
    "            linprom.append(Linear(prom_fc_channels[idx],prom_fc_channels[idx+1]))\n",
    "            linprom.append(torch.nn.ReLU())\n",
    "\n",
    "        self.linprom = Sequential(*linprom)\n",
    "        self.num_prom_fc = num_prom_fc\n",
    "        \n",
    "        \n",
    "        self.readout = Linear(prom_fc_channels[-1]+fc_channels[-1], 1)\n",
    "        \n",
    "    def forward(self, \n",
    "                batch):\n",
    "        barch.prom_x = batch.prom_x.view(-1,self.numchip).float()\n",
    "        batch.edge_attr[torch.isnan(batch.edge_attr)] = 0\n",
    "        batch.x[torch.isnan(batch.x)] = 0\n",
    "        batch.prom_x[torch.isnan(batch.prom_x)] = 0\n",
    "        \n",
    "        batch = self.gconv(batch)\n",
    "\n",
    "        #global pooling\n",
    "        x = global_max_pool(batch.x,\n",
    "                            batch=batch.batch)\n",
    "\n",
    "        # 3. Apply fully connected linear layers to graph\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        # 3. Apply fully connected linear layers to promoter\n",
    "        prom_x = self.linprom(batch.prom_x)\n",
    "        \n",
    "        # 4. Apply readout layers \n",
    "        x = self.readout(torch.cat([x,prom_x],\n",
    "                                   dim = 1)\n",
    "                        )\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightning Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitWEGATNet(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 module,\n",
    "                 learning_rate,\n",
    "                 weight_decay\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.WEGATModule = module\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "    \n",
    "    def shared_step(self, batch):\n",
    "        pred = self.WEGATModule(batch)\n",
    "        \n",
    "        loss = F.l1_loss(pred[:,0],\n",
    "                         batch.y.float())\n",
    "        return loss\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self.shared_step(batch)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self.shared_step(batch)\n",
    "        self.log('val_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss = self.shared_step(batch)\n",
    "        self.log('test_loss', loss)\n",
    "        return loss     \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), \n",
    "                                     lr=self.learning_rate,\n",
    "                                     weight_decay = self.weight_decay\n",
    "                                    )\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in memory datasets\n",
      "Loaded in memory datasets\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "CONSTRUCTING THE DATALOADERS\n",
    "'''\n",
    "print(\"Loading in memory datasets\")\n",
    "dset = torch.load(DATASET,map_location=torch.device('cpu'))\n",
    "\n",
    "numdatapoints = len(dset)\n",
    "trainsize = int(numdatapoints*TRAIN_FRACTION)\n",
    "train_dset, val_dset = random_split(dset,\n",
    "                                    [trainsize, numdatapoints-trainsize],\n",
    "                                    generator=torch.Generator().manual_seed(MANUAL_SEED)\n",
    "                                   )\n",
    "\n",
    "print(\"Loaded in memory datasets\")\n",
    "train_loader = DataLoader(train_dset, \n",
    "                              batch_size=BATCHSIZE,\n",
    "                              num_workers=20\n",
    "                             )\n",
    "val_loader = DataLoader(val_dset, \n",
    "                             batch_size=BATCHSIZE,\n",
    "                            num_workers=20\n",
    "                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name        | Type        | Params\n",
      "--------------------------------------------\n",
      "0 | WEGATModule | WEGATModule | 4.9 K \n",
      "--------------------------------------------\n",
      "4.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.9 K     Total params\n",
      "0.020     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdea50e4e5a0483c9f5f5bef09239c25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1398d8cd31b841f19fd38c0de9c4475c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dh486/gnn-env/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "NUMCHIP = dset[0].x.shape[1]\n",
    "NUMEDGE = dset[0].edge_attr.shape[1]\n",
    "    \n",
    "module = WEGATModule(hidden_channels = 15,\n",
    "                      numchip = NUMCHIP,\n",
    "                      numedge = NUMEDGE\n",
    "                     )\n",
    "Net = LitWEGATNet(module, LEARNING_RATE, WEIGHT_DECAY)\n",
    "\n",
    "tb_logger = pl_loggers.TensorBoardLogger('runs')\n",
    "trainer = pl.Trainer(gpus=0, \n",
    "                         max_epochs=10, \n",
    "                         progress_bar_refresh_rate=20,\n",
    "                         logger=tb_logger)\n",
    "trainer.fit(Net, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 255).\n",
       "Contents of stderr:\n",
       "TensorFlow installation not found - running with reduced feature set.\n",
       "E0519 13:54:06.474670 47233012180864 program.py:311] TensorBoard could not bind to port 8081, it was already in use\n",
       "ERROR: TensorBoard could not bind to port 8081, it was already in use"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start tensorboard.\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir runs/ --port=8081"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
