{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "\n",
    "from src.Dataset import HiC_Dataset\n",
    "from src.layers.WEGATConv import Deep_WEGATv2_Conv\n",
    "from src.layers.utils import PositionalEncoding\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss as CEL\n",
    "from torch.nn import Parameter, Linear, Sequential, Dropout, BatchNorm1d\n",
    "from torch.utils.data import random_split\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "import torch_geometric as tgm\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn import TopKPooling as TKP\n",
    "from torch_geometric.nn import global_max_pool\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "\n",
    "DATASET = \"Data/test_dset_18features_custom_norm.pt\"\n",
    "NUMEPOCHS = 10\n",
    "NUMCLASSES = 3\n",
    "BATCHSIZE = 500\n",
    "LEARNING_RATE = 0.00005\n",
    "WEIGHT_DECAY = 5e-4\n",
    "MANUAL_SEED = 40\n",
    "TRAIN_FRACTION = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "UTILITY FUNCTIONS\n",
    "'''\n",
    "def get_middle_features(x,\n",
    "                        numnodes = 51\n",
    "                       ):\n",
    "    mid = int((numnodes-1)/2)\n",
    "    idxs = torch.arange(mid, x.shape[0], numnodes)\n",
    "    return x[idxs,:]\n",
    "    \n",
    "'''\n",
    "WEIGHTED EDGE GRAPH ATTENTION MODULE\n",
    "'''\n",
    "class WEGATModule(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 hidden_channels=20,\n",
    "                 numchip = 18,\n",
    "                 numedge = 2,\n",
    "                 heads = 4,\n",
    "                 num_graph_convs = 6,\n",
    "                 embedding_layers = 5,\n",
    "                 num_fc = 8,\n",
    "                 fc_channels = [15,15,15,10,10,10,5,2],\n",
    "                 num_prom_fc = 10,\n",
    "                 prom_fc_channels = [15,15,15,15,10,10,10,10,5,2],\n",
    "                 positional_encoding = True,\n",
    "                 pos_embedding_dropout = 0.1,\n",
    "                 fc_dropout = 0.5,\n",
    "                 conv_dropout = 0.1,\n",
    "                 numclasses = NUMCLASSES\n",
    "                ):\n",
    "        if isinstance(fc_channels,int):\n",
    "            fc_channels = [fc_channels]*num_fc\n",
    "        elif len(fc_channels) != num_fc:\n",
    "            print(\"number of fully connected channels must match the number of fully connected layers\")\n",
    "            raise\n",
    "\n",
    "        if num_graph_convs < 1:\n",
    "            print(\"need at least one graph convolution\")\n",
    "            raise\n",
    "        num_graph_convs = int(num_graph_convs)\n",
    "\n",
    "        if isinstance(prom_fc_channels,int):\n",
    "            prom_fc_channels = [prom_fc_channels]*num_prom_fc\n",
    "        elif len(prom_fc_channels) != num_prom_fc:\n",
    "            raise\n",
    "\n",
    "        super().__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        #dropout layer\n",
    "        self.dropout = Dropout(p=fc_dropout)\n",
    "\n",
    "        #number of input chip features\n",
    "        self.numchip = numchip\n",
    "\n",
    "        #Whether to apply positional encoding to nodes\n",
    "        self.positional_encoding = positional_encoding\n",
    "        if positional_encoding:\n",
    "            self.posencoder = PositionalEncoding(hidden_channels,\n",
    "                                                 dropout=pos_embedding_dropout,\n",
    "                                                 identical_sizes = True\n",
    "                                                )\n",
    "\n",
    "        #initial embeddding layer\n",
    "        embedding = []\n",
    "        embedding.append(Linear(numchip,\n",
    "                                hidden_channels)\n",
    "                        )\n",
    "        embedding.append(torch.nn.Dropout(p=fc_dropout))\n",
    "        embedding.append(torch.nn.ReLU())\n",
    "        for idx in torch.arange(embedding_layers - 1):\n",
    "            embedding.append(Linear(hidden_channels,\n",
    "                                    hidden_channels)\n",
    "                            )\n",
    "            embedding.append(torch.nn.Dropout(p=fc_dropout))\n",
    "            embedding.append(BatchNorm1d(hidden_channels))\n",
    "            embedding.append(torch.nn.ReLU())\n",
    "        self.embedding = Sequential(*embedding)\n",
    "\n",
    "        #graph convolution layers\n",
    "        enc = Deep_WEGATv2_Conv(node_in_channels = hidden_channels,\n",
    "                                node_out_channels = hidden_channels,\n",
    "                                edge_in_channels = numedge,\n",
    "                                edge_out_channels = numedge,\n",
    "                                heads = heads,\n",
    "                                node_dropout = conv_dropout,\n",
    "                                edge_dropout = conv_dropout\n",
    "                               )\n",
    "        gconv = [enc]\n",
    "        encdec = Deep_WEGATv2_Conv(node_in_channels = hidden_channels,\n",
    "                                   node_out_channels = hidden_channels,\n",
    "                                   edge_in_channels = numedge,\n",
    "                                   edge_out_channels = numedge,\n",
    "                                   heads = heads,\n",
    "                                   node_dropout = conv_dropout,\n",
    "                                   edge_dropout = conv_dropout\n",
    "                                    )\n",
    "        for idx in np.arange(num_graph_convs-1):\n",
    "            gconv.append(encdec)\n",
    "\n",
    "        self.gconv = Sequential(*gconv)\n",
    "\n",
    "        #fully connected channels\n",
    "        fc_channels = [hidden_channels]+fc_channels\n",
    "        lin = []\n",
    "        for idx in torch.arange(num_fc):\n",
    "            lin.append(Linear(fc_channels[idx],fc_channels[idx+1]))\n",
    "            lin.append(torch.nn.Dropout(p=fc_dropout))\n",
    "            lin.append(BatchNorm1d(fc_channels[idx+1]))\n",
    "            lin.append(torch.nn.ReLU())\n",
    "        self.lin = Sequential(*lin)\n",
    "        self.num_fc = num_fc\n",
    "\n",
    "        #fully connected promoter channels\n",
    "        prom_fc_channels = [numchip]+prom_fc_channels\n",
    "        linprom = []\n",
    "        for idx in torch.arange(num_prom_fc):\n",
    "            linprom.append(Linear(prom_fc_channels[idx],prom_fc_channels[idx+1]))\n",
    "            linprom.append(torch.nn.Dropout(p=fc_dropout))\n",
    "            lin.append(BatchNorm1d(prom_fc_channels[idx+1]))\n",
    "            linprom.append(torch.nn.ReLU())\n",
    "        self.linprom = Sequential(*linprom)\n",
    "        self.num_prom_fc = num_prom_fc\n",
    "\n",
    "        #final readout function\n",
    "        self.readout = Linear(prom_fc_channels[-1]+fc_channels[-1], numclasses)\n",
    "\n",
    "    def forward(self,\n",
    "                batch):\n",
    "        batch.prom_x = batch.prom_x.view(-1,self.numchip).float()\n",
    "        batch.edge_attr[torch.isnan(batch.edge_attr)] = 0\n",
    "        batch.x[torch.isnan(batch.x)] = 0\n",
    "        batch.prom_x[torch.isnan(batch.prom_x)] = 0\n",
    "        \n",
    "        #initial dropout and embedding\n",
    "        batch.x = self.dropout(batch.x)\n",
    "        batch.x = self.embedding(batch.x.float())\n",
    "\n",
    "        #positional encoding\n",
    "        if self.positional_encoding:\n",
    "            batch.x = self.posencoder(batch.x,\n",
    "                                      batch.batch)\n",
    "\n",
    "        #graph convolutions\n",
    "        batch = self.gconv(batch)\n",
    "\n",
    "        #extracting node of interest from graph\n",
    "        x = get_middle_features(batch.x)\n",
    "\n",
    "        # 3. Apply fully connected linear layers to graph\n",
    "        x = self.lin(x)\n",
    "\n",
    "        # 3. Apply fully connected linear layers to promoter\n",
    "        prom_x = self.linprom(batch.prom_x)\n",
    "\n",
    "        r_x = torch.cat([x,prom_x],\n",
    "                        dim = 1)\n",
    "        \n",
    "        # 4. Apply readout layers\n",
    "        x = self.readout(r_x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightning Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "LIGHTNING NET\n",
    "'''\n",
    "class LitWEGATNet(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 module,\n",
    "                 train_loader,\n",
    "                 val_loader,\n",
    "                 learning_rate,\n",
    "                 numsteps,\n",
    "                 criterion\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.module = module\n",
    "        self.learning_rate = learning_rate\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.numsteps = numsteps\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.train_loader\n",
    "    \n",
    "    def validation_dataloader(self):\n",
    "        return self.test_loader\n",
    "\n",
    "    def shared_step(self, batch):\n",
    "        pred = self.module(batch).squeeze()\n",
    "        loss = self.criterion(pred, batch.y)\n",
    "        return loss, pred\n",
    "\n",
    "    def customlog(self, name, loss, pred):\n",
    "        self.log(f'{name}_loss', loss)\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, pred = self.shared_step(batch)\n",
    "        self.customlog('train',loss, pred)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, pred = self.shared_step(batch)\n",
    "        self.customlog('val',loss, pred)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, pred = self.shared_step(batch)\n",
    "        self.customlog('test',loss, pred)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(),\n",
    "                                     lr=self.learning_rate)\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': OneCycleLR(optimizer,\n",
    "                                        max_lr = 10*self.learning_rate,\n",
    "                                        total_steps = self.numsteps\n",
    "                                       )\n",
    "            }\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in memory datasets\n",
      "Loaded in memory datasets\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "CONSTRUCTING THE DATALOADERS\n",
    "'''\n",
    "print(\"Loading in memory datasets\")\n",
    "dset = torch.load(DATASET,map_location=torch.device('cpu'))\n",
    "\n",
    "vals = []\n",
    "for d in dset:\n",
    "    v = d.y.item()\n",
    "    vals.append(v)\n",
    "down, up = np.percentile(vals, 10),np.percentile(vals,90)\n",
    "\n",
    "classes = ('downregulated','insignificant change','upregulated')\n",
    "nums = [0,0,0]\n",
    "for d in dset:\n",
    "    v = d.y.item()\n",
    "    if v <= down:\n",
    "        idx = 0\n",
    "    elif v >= up:\n",
    "        idx = 2\n",
    "    else:\n",
    "        idx = 1\n",
    "    d.y = idx\n",
    "    nums[idx] += 1\n",
    "\n",
    "criterion = CEL(weight = Tensor([np.max(nums)/item for item in nums]))    \n",
    "numdatapoints = len(dset)\n",
    "trainsize = int(numdatapoints*TRAIN_FRACTION)\n",
    "train_dset, val_dset = random_split(dset,\n",
    "                                    [trainsize, numdatapoints-trainsize],\n",
    "                                    generator=torch.Generator().manual_seed(MANUAL_SEED)\n",
    "                                   )\n",
    "\n",
    "print(\"Loaded in memory datasets\")\n",
    "train_loader = DataLoader(train_dset, \n",
    "                              batch_size=BATCHSIZE,\n",
    "                              num_workers=20\n",
    "                             )\n",
    "val_loader = DataLoader(val_dset, \n",
    "                             batch_size=BATCHSIZE,\n",
    "                            num_workers=20\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1053,  0.1748, -0.3319],\n",
      "        [ 0.0829,  0.2445, -0.3212],\n",
      "        [ 0.1354,  0.0813, -0.3463],\n",
      "        ...,\n",
      "        [ 0.1603,  0.0040, -0.3583],\n",
      "        [ 0.0598,  0.3160, -0.3101],\n",
      "        [ 0.0567,  0.3258, -0.3086]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.0229,  0.4741,  0.1653],\n",
      "        [ 0.1530,  0.0431, -0.1814],\n",
      "        [ 0.0143,  0.5117,  0.2854],\n",
      "        ...,\n",
      "        [ 0.1481,  0.0418, -0.3524],\n",
      "        [ 0.0567,  0.3258, -0.3086],\n",
      "        [ 0.1367,  0.0867, -0.2475]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-4b3490f39f9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m                         )\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gnn-env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-a42ae8895184>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;31m#graph convolutions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;31m#extracting node of interest from graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gnn-env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gnn-env/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gnn-env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/rds/user/dh486/hpc-work/GrapHiC-ML/src/layers/WEGATConv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_aggr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_aggr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_attr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gnn-env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/rds/user/dh486/hpc-work/GrapHiC-ML/src/layers/utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'constant'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gnn-env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gnn-env/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 822\u001b[0;31m                              self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    823\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             result = _VF.gru(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NUMCHIP = dset[0].x.shape[1]\n",
    "NUMEDGE = dset[0].edge_attr.shape[1]\n",
    "module = WEGATModule(hidden_channels = 20,\n",
    "                         numchip = NUMCHIP,\n",
    "                         numedge = NUMEDGE,\n",
    "                         embedding_layers = 4,\n",
    "                         positional_encoding = True,\n",
    "                         pos_embedding_dropout = 0,\n",
    "                         fc_dropout = 0.01,\n",
    "                         conv_dropout = 0.01\n",
    "                        )\n",
    "for dat in val_loader:\n",
    "    print(module(dat))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | module    | WEGATModule      | 18.5 K\n",
      "1 | criterion | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "18.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.5 K    Total params\n",
      "0.074     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8353b9f67fd44e8d800d7ebe339f14c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dh486/gnn-env/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "NUMCHIP = dset[0].x.shape[1]\n",
    "NUMEDGE = dset[0].edge_attr.shape[1]\n",
    "\n",
    "module = WEGATModule(hidden_channels = 20,\n",
    "                     numchip = NUMCHIP,\n",
    "                     numedge = NUMEDGE,\n",
    "                     embedding_layers = 4,\n",
    "                     positional_encoding = True,\n",
    "                     pos_embedding_dropout = 0.05,\n",
    "                     fc_dropout = 0.05,\n",
    "                     conv_dropout = 0.05\n",
    "                        )\n",
    "Net = LitWEGATNet(module,\n",
    "                  train_loader,\n",
    "                  val_loader,\n",
    "                  LEARNING_RATE,\n",
    "                  50000,\n",
    "                  criterion\n",
    "                 )\n",
    "    \n",
    "\n",
    "tb_logger = pl_loggers.TensorBoardLogger('runs',\n",
    "                                         name = 'printing_test',\n",
    "                                         version = 0\n",
    "                                        )\n",
    "trainer = pl.Trainer(gpus=0,\n",
    "                     max_epochs=100,\n",
    "                     progress_bar_refresh_rate=1,\n",
    "                     #logger=tb_logger,\n",
    "                     auto_lr_find=False)\n",
    "\n",
    "trainer.fit(Net, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 255).\n",
       "Contents of stderr:\n",
       "TensorFlow installation not found - running with reduced feature set.\n",
       "E0519 13:54:06.474670 47233012180864 program.py:311] TensorBoard could not bind to port 8081, it was already in use\n",
       "ERROR: TensorBoard could not bind to port 8081, it was already in use"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start tensorboard.\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir runs/ --port=8081"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
